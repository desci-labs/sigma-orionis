{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pdb, glob\n",
    "import numpy as np\n",
    "from astropy.table import Table, join\n",
    "from astroquery.vizier import Vizier\n",
    "from scripts import calc_dust_masses\n",
    "import warnings\n",
    "from astropy.logger import AstropyWarning\n",
    "warnings.filterwarnings('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(catalog, join_key='Name'):\n",
    "\n",
    "    \"\"\"\n",
    "    PURPOSE:    Get data from literature with Vizier\n",
    "\n",
    "    INPUT:      catalog = ctalog name on Vizier (str)\n",
    "                join_key = column header to join tables, if multiple (str; optional)\n",
    "\n",
    "    OUTPUT:     t = data table (AstroPy Table)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### GET FULL CATALOG (ALL COLUMNS, ALL ROWS)\n",
    "    viz = Vizier(catalog=catalog, columns=['**'])\n",
    "    viz.ROW_LIMIT = -1\n",
    "    tv = viz.get_catalogs(catalog)\n",
    "\n",
    "    ### IF MULTIPLE TABLES, JOIN THEN\n",
    "    for i, val in enumerate(tv.keys()):\n",
    "        if i == 0:\n",
    "            t = tv[val]\n",
    "        else:\n",
    "            tt = tv[val]\n",
    "            if join_key in tt.columns:\n",
    "                t = join(t, tt, join_type='inner', keys=join_key)\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dustmass(b, l, f, d, t):\n",
    "    \n",
    "    \"\"\"\n",
    "    PURPOSE:    Calculate disk dust mass using prescription from\n",
    "                Hildebrand 1983 (1983QJRAS..24..267H)\n",
    "\n",
    "    INPUT:      b = dust opacity power-law index (unitless; float)\n",
    "                l = wavelength of observations (microns; float)\n",
    "                f = observed flux (mJy; float)\n",
    "                d = distance to disk (pc; float)\n",
    "                t = disk temperature (K; float)\n",
    "\n",
    "    OUTPUT:     Disk dust mass in Earth masses (float)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    b, l, f, d, t = fix_units(b, l, f, d, t)\n",
    "    k_nu = get_kappa(l, b)\n",
    "    b_nu = get_planck(l, t)\n",
    "    mult = get_mult(d, k_nu, b_nu)\n",
    "    mdust = mult * f * (const.M_sun.cgs / const.M_earth.cgs)\n",
    "\n",
    "    return round(mdust.value, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_table(t, region, col_name, col_spt, col_flux, col_eflux, col_mstar, col_emstar, dist, obs_wave, col_lflux=None, log_mstar=False):\n",
    "\n",
    "    \"\"\"\n",
    "    PURPOSE:    Make tables for different regions consistent\n",
    "\n",
    "    INPUT:      t = table from literature (AstroPy Table)\n",
    "                region = name of region (str)\n",
    "                col_X = column name for data values (str)\n",
    "                dist = distance to source in pc (float arr)\n",
    "                obs_wave = wavelength of observation in microns (float)\n",
    "                col_lflux = column name if fluxes for non-detections are upper limits (str; optional)\n",
    "                log_mstar = boolean flag if stellar mass is log (boolean; optional)\n",
    "\n",
    "    OUTPUT:     t = fixed data table (AstroPy Table)\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    ### DO SOME EXTRA FIXING FOR SOME REGIONS\n",
    "    t['ObsWave'] = obs_wave\n",
    "    det_lim = 3.0\n",
    "    if region == 'tau':\n",
    "\n",
    "        ### USE 1.3mm CONTINUUM FLUXES THAT WERE MEASURED RATHER THAN ESTIMATED\n",
    "        ind_1300 = np.where(t['Notes'] == 'e, m')\n",
    "        t[col_flux][ind_1300] = t['F1.3'][ind_1300]\n",
    "        t[col_lflux][ind_1300] = t['l_F1.3'][ind_1300]\n",
    "        t['ObsWave'][ind_1300] = 1300.\n",
    "\n",
    "        ### CONVERT TO mJy\n",
    "        t[col_flux] *= 1e3\n",
    "        t[col_eflux] *= 1e3\n",
    "\n",
    "        ### FIX SPECTRAL TYPES\n",
    "        t[col_spt] = [x.replace(')', '').replace('(', '').split('+/-')[0].split('-')[0] for x in t['SpT']]\n",
    "\n",
    "        ### TAKE AVERAGE OF UPPER/LOWER STELLAR MASS UNCERTAINTIES\n",
    "        t[col_emstar] = np.mean([abs(t['logM_3'] - t['b_logM_3']), abs(t['B_logM_3'] - t['logM_3'])], axis=0)\n",
    "\n",
    "        ### FIX FLUX ERRORS\n",
    "        t[col_eflux][t[col_name] == 'IRAS 04216+2603'] = 0.1 * t[col_flux][t[col_name] == 'IRAS 04216+2603'].data[0]\n",
    "\n",
    "    if region == 'cha':\n",
    "\n",
    "        ### ASSUME 20% STELLAR MASS ERRORS FOR THOSE WITH UNKNOWN ERRORS\n",
    "        t.remove_column('Name')\n",
    "        ind = np.where(t['b_logM_'] == 0.0)\n",
    "        t['b_logM_'][ind] = t['logM_'][ind] - 0.434 * 0.2\n",
    "        t['B_logM_'][ind] = t['logM_'][ind] - 0.434 * 0.2\n",
    "\n",
    "        ### TAKE AVERAGE OF UPPER/LOWER STELLAR MASS UNCERTAINTIES\n",
    "        t[col_emstar] = np.mean([abs(t['logM_'] - t['b_logM_']), abs(t['B_logM_'] - t['logM_'])], axis=0)\n",
    "\n",
    "    if region == 'usc':\n",
    "\n",
    "        ### TAKE AVERAGE OF UPPER/LOWER STELLAR MASS UNCERTAINTIES\n",
    "        t[col_emstar] = np.mean(np.array([t['E_logM'], t['e_logM']]), axis=0)\n",
    "\n",
    "    if region == 'sor':\n",
    "\n",
    "        det_lim = 2.9\n",
    "\n",
    "    ### FIX COLUMN NAMES\n",
    "    t[col_name].name = 'Name'\n",
    "    t[col_spt].name = 'SpT'\n",
    "    t[col_mstar].name = 'Mstar'\n",
    "    t[col_emstar].name = 'e_Mstar'\n",
    "    t[col_flux].name = 'Flux'\n",
    "    t[col_eflux].name = 'e_Flux'\n",
    "    t['Dist'] = dist\n",
    "\n",
    "    ### FLAG (NON-)DETECTIONS \n",
    "    ### CAN REPLACE WITH 3-SIGMA UPPER LIMITS; USE 3x ERROR IF TRUE ERRORS REPORTED\n",
    "    if col_lflux is None:\n",
    "        t['Det'] = np.repeat(0, len(t))\n",
    "        t['Det'][t['Flux'] / t['e_Flux'] >= det_lim] = 1\n",
    "        # t['Flux'][np.where(t['Det'] == 0)] = 3.0 * t['e_Flux'][np.where(t['Det'] == 0)]\n",
    "    ### USE REPORTED FLUX IF UPPER LIMITS PROVIDED\n",
    "    else:\n",
    "        t['Det'] = np.repeat(1, len(t))\n",
    "        t['Det'][np.where(t[col_lflux] == '<')] = 0\n",
    "\n",
    "    ### FOR UPPER SCO, ONLY KEEP \"PRIMORDIAL\" DISKS \n",
    "    ### TO MATCH SAMPLES OF LUPUS & TAURUS\n",
    "    if region == 'usc':\n",
    "        t = t[np.where( (t['Type'] == 'Full') | (t['Type'] == 'Transitional') | (t['Type'] == 'Evolved'))] \n",
    "    # print(len(t['Det'][t['Det'] == 0]))\n",
    "\n",
    "    ### ONLY KEEP STARS > 0.1 SOLAR MASS\n",
    "    ### AND KEEP LUPUS SOURCES THAT HAVE UNKNOWN STELLAR MASSES\n",
    "    if log_mstar:\n",
    "        t['Mstar'] = 10**t['Mstar']\n",
    "        t['e_Mstar'] = t['Mstar'] * t['e_Mstar'] / 0.434\n",
    "    t = t[np.where((t['Mstar'] >= 0.1) | (t['Mstar'].mask == True))]\n",
    "    # print(len(t['Det'][t['Det'] == 0]))\n",
    "\n",
    "    ### CALCULATE DUST MASSES USING SAME METHOD AS LUPUS\n",
    "    mdust, e_mdust = [], []\n",
    "    for i, val in enumerate(t):\n",
    "        mdust.append(calc_dust_masses.get_dustmass(1.0, t['ObsWave'][i], t['Flux'][i], t['Dist'][i], 20.))\n",
    "        ### USE MEASURED ERRORS IF PROVIDED\n",
    "        if col_lflux is None:\n",
    "            e_mdust.append(calc_dust_masses.get_dustmass(1.0, t['ObsWave'][i], t['e_Flux'][i], t['Dist'][i], 20.))\n",
    "        elif t[col_lflux][i] == '':\n",
    "            e_mdust.append(calc_dust_masses.get_dustmass(1.0, t['ObsWave'][i], t['e_Flux'][i], t['Dist'][i], 20.))\n",
    "        ### USE FLUX/3 IF ONLY UPPER LIMITS PROVIDED FOR NON-DETECTIONS\n",
    "        else:\n",
    "            e_mdust.append(calc_dust_masses.get_dustmass(1.0, t['ObsWave'][i], t['Flux'][i] / 3.0, t['Dist'][i], 20.))   \n",
    "    t['MDust'] = mdust\n",
    "    t['e_MDust'] = e_mdust\n",
    "\n",
    "    return t['Name', 'SpT', 'Dist', 'Mstar', 'e_Mstar', 'Flux', 'ObsWave', 'Det', 'MDust', 'e_MDust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Sigma Orionis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = get_data(\"J/AJ/153/240\")\n",
    "TS = fix_table(TS, 'sor', '__HHM2007_', 'SpT', 'F1.33', 'e_F1.33', 'Mass', 'e_Mass', np.repeat(385., len(TS)), 1330.)\n",
    "TS.write('../output/data_sor.txt', format='ascii.ipac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Lupus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL = get_data(\"J/ApJ/828/46\")\n",
    "TL = fix_table(TL, 'lup', 'Name', 'SpT', 'F890', 'e_F890', 'Mass', 'e_Mass', TL['Dist'], 890.)\n",
    "TL.write('../output/data_lup.txt', format='ascii.ipac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Taurus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Carla/Desktop/2017_sigmaOri/codes/calc_dust_masses.py:66: UserWarning: Warning: converting a masked element to nan.\n",
      "  f = float(f) * u.mJy\n"
     ]
    }
   ],
   "source": [
    "TT = get_data(\"J/ApJ/771/129/\")\n",
    "TT = fix_table(TT, 'tau', 'Name', 'SpT', 'F0.89', 'e_F0.89', 'logM_3', 'e_logM', np.repeat(140., len(TT)), 890., col_lflux='l_F0.89', log_mstar=True)\n",
    "TT.write('../output/data_tau.txt', format='ascii.ipac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Cham-I data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TC = get_data(\"J/ApJ/831/125\")\n",
    "TC = fix_table(TC, 'cha', '_2MASS', 'SpT', 'Fnu', 'e_Fnu', 'logM_', 'e_logM', np.repeat(160., len(TC)), 887., log_mstar=True)\n",
    "TC.write('../output/data_cha.txt', format='ascii.ipac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Upper Sco data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TU = get_data(\"J/ApJ/827/142\")\n",
    "TU = fix_table(TU, 'usc', '_2MASS', 'SpT', 'Snu', 'e_Snu', 'logM', 'e_logM', np.repeat(145., len(TU)), 880., log_mstar=True)\n",
    "TU.write('../output/data_usc.txt', format='ascii.ipac')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
